5.4 池化层
5.4.1二维最大池化层和平均池化层
    池化（pooling）层，它的提出是为了缓解卷积层对位置的过度敏感性。
    计算方式：池化层直接计算池化窗口内元素的最大值或者平均值，该过程也分别叫做最大池化或平均池化。因此将池化窗口形状为p*q的池化层称为p*q池化层，其中的池化运算叫做p*q池化。
code:
import torch
from torch import nn

def pool2d(X, pool_size, mode='max'):
    X = X.float()
    p_h, p_w =  pool_size
    Y = torch.zeros(X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            if mode == 'max':
                Y[i][j] = X[i:i + p_h, j: j + p_w].max()
            elif mod == 'avg':
                Y[i][j] = X[i:i + p_h,j:j + p_w].mean()
    return Y
X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])
pool2d(X, (2, 2))
pool2d(X, (2, 2), 'avg')                             
output：
tensor([[4., 5.],
        [7., 8.]])
tensor([[2., 3.],
        [5., 6.]])
5.4.2填充（padding）和步幅（stride）
     同卷积层的定义和操作
5.4.3多通道
     池化层对每个输入通道分别池化，这意味着池化层的输出通道数与输入通道数相等。不同于卷积层，卷积层的输出通道数始终为1.

5.5 卷积神经网络（CNN：convolutional neural network）
5.10批量归一化（batch normalization)
    在模型训练时，批量归一化利用小批量上的均值和标准差，不断调整神经网络中间输出，从而使整个神经网络在各层的中间输出 的数值更加 稳定。
5.10.1对全连接层做批量归一化
      
      
    
   








     
